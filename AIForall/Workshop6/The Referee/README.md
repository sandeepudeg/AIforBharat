# Database Referee âš–ï¸

A decision-support tool that helps teams choose between PostgreSQL, DynamoDB, and Redis based on their specific constraints.

## Overview

Rather than declaring a single "winner," the Database Referee analyzes trade-offs explicitly, showing pros and cons relative to your constraints. This enables informed decision-making in database selection.

## Features

âœ… **Constraint-Based Analysis**: Input your specific requirements (data structure, consistency, scale, latency, etc.)
âœ… **Disqualification Rules**: Automatically eliminates unsuitable databases based on hard constraints
âœ… **Weighted Scoring**: Calculates scores based on multiple factors with adjustable weights
âœ… **Trade-off Analysis**: Shows pros and cons of each option relative to your constraints
âœ… **Comparison Table**: Visual comparison of all databases across key factors
âœ… **Configuration Persistence**: Save and load your constraint configurations

## Quick Start

### Option 1: Command-Line Interface (No Dependencies)

```bash
python cli_app.py
```

This version works without installing Streamlit. Just answer the questions and get your analysis!

### Option 2: Streamlit Web Interface (Recommended)

```bash
# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

The app will open at `http://localhost:8501`

## Installation

### Prerequisites

- Python 3.9 or higher
- pip (Python package manager)

### Setup

1. **Clone or download the project**

2. **Navigate to the project directory**
   ```bash
   cd "The Referee"
   ```

3. **Create a virtual environment (recommended)**
   ```bash
   python -m venv venv
   
   # Activate it
   # On Windows:
   venv\Scripts\activate
   # On macOS/Linux:
   source venv/bin/activate
   ```

4. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Run the application**
   ```bash
   # Web interface
   streamlit run app.py
   
   # OR command-line interface
   python cli_app.py
   ```

## Usage

### Web Interface (Streamlit)

1. Open the app at `http://localhost:8501`
2. Fill in the constraint form with your requirements
3. Click "Analyze & Get Recommendation"
4. View the results including:
   - Disqualified options with reasons
   - Winner with score and rationale
   - Pros and cons
   - Score breakdown
   - Comparison table

### Command-Line Interface

1. Run `python cli_app.py`
2. Answer each question about your database needs
3. View your constraint summary
4. See the next steps for analysis

## Constraint Inputs

The tool asks for the following constraints:

| Constraint | Options | Description |
|-----------|---------|-------------|
| Data Structure | Relational, JSON, Key-Value | Type of data you're storing |
| Read/Write Ratio | 0-100 | Percentage of read operations |
| Consistency Level | Strong, Eventual | Consistency requirements |
| Query Complexity | Simple, Moderate, Complex | Complexity of your queries |
| Data Scale | Positive number (GB) | Expected data size |
| Latency Requirement | Positive number (ms) | Maximum acceptable latency |
| Team Expertise | Low, Medium, High | Your team's database knowledge |
| Persistence Required | Yes/No | Whether data must be persistent |

## Databases Compared

### PostgreSQL
- **Strengths**: Full SQL support, ACID transactions, complex joins, strong consistency
- **Weaknesses**: Vertical scaling, higher latency, requires schema management
- **Best for**: Relational data with complex queries

### DynamoDB
- **Strengths**: Horizontal scaling, low latency, managed service
- **Weaknesses**: Limited query flexibility, eventual consistency, no joins
- **Best for**: High-scale, simple key-value access

### Redis
- **Strengths**: Ultra-low latency, in-memory performance, caching
- **Weaknesses**: Limited persistence, memory constraints, not for primary storage
- **Best for**: Caching and real-time data

## Disqualification Rules

The tool automatically disqualifies databases that don't meet your hard constraints:

1. **Joins Required** â†’ Disqualifies DynamoDB
2. **Strong Consistency** â†’ Disqualifies DynamoDB
3. **Persistence Critical** â†’ Disqualifies Redis
4. **Scale > 10GB** â†’ Disqualifies Redis
5. **Latency < 1ms** â†’ Disqualifies PostgreSQL

## Scoring Algorithm

Remaining databases are scored using:

```
base_score = (
    data_structure_match Ã— 0.30 +
    consistency_match Ã— 0.25 +
    query_flexibility Ã— 0.20 +
    cost_score Ã— 0.15 +
    latency_score Ã— 0.10
)

Adjustments:
- If joins needed: multiply query_flexibility Ã— 3.0
- If strong consistency: multiply consistency Ã— 2.0
- If scale > 100GB: multiply scaling Ã— 1.5

final_score = normalize(adjusted_score, 0-10 scale)
```

## Testing

### Run All Tests

```bash
pytest tests/ -v
```

### Run Property-Based Tests

```bash
pytest tests/properties/ -v
```

### Run with Coverage Report

```bash
pytest tests/ --cov=src --cov-report=html
```

### Run Basic Test (No Dependencies)

```bash
python test_basic.py
```

## Project Structure

```
The Referee/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                    # Data models (Constraint, Report, etc.)
â”‚   â””â”€â”€ constraint_parser.py         # Constraint validation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                        # Unit tests
â”‚   â”œâ”€â”€ properties/                  # Property-based tests
â”‚   â”‚   â””â”€â”€ test_constraint_properties.py
â”‚   â””â”€â”€ integration/                 # Integration tests
â”œâ”€â”€ data/                            # Configuration storage
â”œâ”€â”€ app.py                           # Streamlit web interface
â”œâ”€â”€ cli_app.py                       # Command-line interface
â”œâ”€â”€ test_basic.py                    # Basic test script
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ pytest.ini                       # Test configuration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ SETUP_GUIDE.md                   # Detailed setup instructions
â””â”€â”€ .kiro/                           # Specification documents
    â””â”€â”€ specs/database-referee/
        â”œâ”€â”€ requirements.md          # Feature requirements
        â”œâ”€â”€ design.md                # System design
        â””â”€â”€ tasks.md                 # Implementation tasks
```

## Specification Documents

The project includes comprehensive specification documents in `.kiro/specs/database-referee/`:

- **requirements.md**: 7 requirements with 35+ acceptance criteria using EARS patterns
- **design.md**: Complete architecture, components, data models, and correctness properties
- **tasks.md**: 12 implementation tasks with 40+ sub-tasks

These documents guide the implementation and ensure all requirements are met.

## Development Status

### âœ… Completed
- Project structure and setup
- Constraint data model with validation
- Constraint parser with error handling
- Property-based tests (5 tests)
- Streamlit UI with constraint input form
- Command-line interface

### ğŸ”„ In Progress
- Disqualification engine
- Scoring engine
- Report generator
- Complete UI with results display

### â³ Planned
- Persistence layer (save/load configurations)
- Full test suite (80%+ coverage)
- Documentation and deployment

## Examples

### Example 1: Relational Data with Joins

**Input**:
- Data Structure: Relational
- Read/Write Ratio: 50%
- Consistency: Strong
- Query Complexity: Complex
- Scale: 10 GB
- Latency: 5 ms
- Team Expertise: Medium
- Persistence: Yes

**Expected Output**:
- ğŸ† Winner: PostgreSQL (8.5/10)
- âŒ Disqualified: DynamoDB (can't do joins), Redis (not persistent)

### Example 2: High-Scale Cache

**Input**:
- Data Structure: Key-Value
- Read/Write Ratio: 90%
- Consistency: Eventual
- Query Complexity: Simple
- Scale: 5 GB
- Latency: 1 ms
- Team Expertise: High
- Persistence: No

**Expected Output**:
- ğŸ† Winner: Redis (9.0/10)
- âŒ Disqualified: PostgreSQL (latency < 1ms)

## Troubleshooting

### "ModuleNotFoundError: No module named 'streamlit'"

**Solution**: Install dependencies
```bash
pip install -r requirements.txt
```

### "ModuleNotFoundError: No module named 'src'"

**Solution**: Make sure you're running from the project root directory
```bash
cd "The Referee"
streamlit run app.py
```

### "python: command not found"

**Solution**: Use `python3` instead
```bash
python3 -m streamlit run app.py
```

### Port 8501 already in use

**Solution**: Use a different port
```bash
streamlit run app.py --server.port 8502
```

## Contributing

This project is part of a spec-driven development exercise. All changes should:

1. Reference the specification documents in `.kiro/specs/database-referee/`
2. Include property-based tests for new functionality
3. Maintain 80%+ code coverage
4. Follow the EARS pattern for requirements

## License

This project is created for educational purposes.

## Support

For detailed setup instructions, see `SETUP_GUIDE.md`

For specification details, see `.kiro/specs/database-referee/`

## Quick Commands

```bash
# Install dependencies
pip install -r requirements.txt

# Run web interface
streamlit run app.py

# Run command-line interface
python cli_app.py

# Run tests
pytest tests/ -v

# Run basic test
python test_basic.py

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

---

**Database Referee v0.1.0** - Making database decisions easier, one constraint at a time. âš–ï¸
